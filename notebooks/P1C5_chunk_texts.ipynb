{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Démonstration des techniques de découpage de texte avec Python\n","\n","Dans ce notebook, nous explorons plusieurs techniques de découpage de texte, utiles dans le cadre de tâches de NLP (traitement du langage naturel), de résumé, ou d'indexation pour des agents conversationnels.\n","\n","Nous allons couvrir :\n","\n","- Le découpage récursif avec chevauchement (LangChain)\n","\n","- Le découpage basé sur les balises (HTML/Markdown)\n","\n","- Le découpage sémantique avec un modèle NLP (spaCy)"],"metadata":{"id":"ePITRl6Dhegp"}},{"cell_type":"code","source":["!pip install langchain --quiet\n","\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Initialisation du splitter\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,      # Taille de chaque segment\n","    chunk_overlap=200     # Chevauchement entre les segments\n",")\n","\n","# Exemple d'utilisation\n","texte = \"\"\"Votre texte ici. Ceci est un exemple illustrant la manière dont le texte est découpé en morceaux...\"\"\"\n","segments = text_splitter.split_text(texte)\n","\n","for i, segment in enumerate(segments):\n","    print(f\"Segment {i+1}:\\n{segment}\\n\")"],"metadata":{"id":"niKrW8nkgpN3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install beautifulsoup4 --quiet\n","\n","from bs4 import BeautifulSoup\n","\n","def chunk_by_tags(html_content, tags):\n","    soup = BeautifulSoup(html_content, 'html.parser')\n","    segments = []\n","    for tag in tags:\n","        elements = soup.find_all(tag)\n","        for elem in elements:\n","            segments.append(elem.get_text())\n","    return segments\n","\n","# Exemple\n","html_content = \"<h1>Titre</h1><p>Paragraphe 1</p><p>Paragraphe 2</p>\"\n","tags = ['h1', 'p']\n","segments = chunk_by_tags(html_content, tags)\n","\n","for i, segment in enumerate(segments):\n","    print(f\"Segment {i+1}:\\n{segment}\\n\")"],"metadata":{"id":"gU8z_UuagpRK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install spacy --quiet\n","!python -m spacy download fr_core_news_sm\n","\n","import spacy\n","\n","# Charger le modèle français\n","nlp = spacy.load(\"fr_core_news_sm\")\n","\n","def semantic_chunking(text, max_chunk_size=150):\n","    doc = nlp(text)\n","    segments = []\n","    current_segment = []\n","\n","    for sent in doc.sents:\n","        if len(\" \".join(current_segment)) + len(sent.text) <= max_chunk_size:\n","            current_segment.append(sent.text)\n","        else:\n","            segments.append(\" \".join(current_segment))\n","            current_segment = [sent.text]\n","    if current_segment:\n","        segments.append(\" \".join(current_segment))\n","    return segments\n","\n","# Exemple\n","texte = \"Ceci est une première phrase. Voici une autre phrase importante. Encore une phrase pour tester.\"\n","segments = semantic_chunking(texte)\n","\n","for i, segment in enumerate(segments):\n","    print(f\"Segment {i+1}:\\n{segment}\\n\")"],"metadata":{"id":"MXQx_0CdgpUZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dkZEMraOgpXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pH4m_5Q4gpa8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I-5hf6p4gpeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yEfjttoagphz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O6Jo846mgplV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z0NVpxedgpov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5OgzwukXgpsR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wyK-RRBvgpvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c7sGf179gpzL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ywfb7HzJgp2e"},"execution_count":null,"outputs":[]}]}