{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tester des Modèles d'Embedding\n","---\n","\n","Ce notebook accompagne la vidéo tutoriel sur le test et l'utilisation de modèles d'embedding avec Hugging Face et Mistral AI dans le cadre du projet RAG (Retrieval-Augmented Generation) pour la mairie de Trifouillis-sur-Loire.\n","\n","### Objectif : Explorer comment générer des représentations vectorielles (embeddings) de textes pour améliorer la recherche d'informations pertinentes.\n","\n","#### Outils utilisés :\n","\n","*   Hugging Face: Pour accéder à des modèles d'embedding open source via la bibliothèque sentence-transformers.\n","*   Mistral AI: Pour utiliser des modèles d'embedding performants via leur API serverless.\n","\n","#### Objectifs :\n","En comparant la similarité entre vecteur_requête et les vecteur_document disponibles, le système RAG peut identifier le document le plus pertinent pour répondre à la question, même si les mots exacts ne sont pas identiques.\n","\n"],"metadata":{"id":"g2yWzE2EZ_Of"}},{"cell_type":"code","source":["# @title Installation des bibliothèques\n","!pip install sentence-transformers numpy -q\n","print(\"Bibliothèques installées !\")"],"metadata":{"id":"kNrz75faYeW9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Chargement du modèle et vectorisation de textes\n","from sentence_transformers import SentenceTransformer\n","import numpy as np\n","\n","# Charger le modèle depuis Hugging Face Hub\n","print(\"Chargement du modèle Sentence Transformer...\")\n","model_hf = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","print(\"Modèle chargé !\")\n","\n","# Textes d'exemple (simulant une question et un extrait de document)\n","textes_hf = [\n","    \"Quelles sont les heures d'ouverture de la mairie ?\", # Simulation question citoyen\n","    \"La mairie de Trifouillis-sur-Loire est ouverte du lundi au vendredi de 8h30 à 17h00.\", # Simulation info document\n","    \"Le marché hebdomadaire a lieu tous les samedis matin sur la place centrale.\" # Info non pertinente\n","]\n","\n","# Générer les embeddings\n","print(\"\\nGénération des embeddings...\")\n","embeddings_hf = model_hf.encode(textes_hf)\n","\n","print(\"Embeddings générés !\")\n","print(\"Shape du premier embedding :\", embeddings_hf[0].shape) # Montre la dimension du vecteur\n","# Optionnel : Afficher les embeddings (peut être très long)\n","# print(\"\\nEmbeddings :\")\n","# print(embeddings_hf)"],"metadata":{"id":"y_uk5k1cYeah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Calcul de la similarité cosinus\n","\n","def cosine_similarity(vec1, vec2):\n","  \"\"\"Calcule la similarité cosinus entre deux vecteurs.\"\"\"\n","  dot_product = np.dot(vec1, vec2)\n","  norm_vec1 = np.linalg.norm(vec1)\n","  norm_vec2 = np.linalg.norm(vec2)\n","  if norm_vec1 == 0 or norm_vec2 == 0:\n","    return 0 # Éviter la division par zéro\n","  return dot_product / (norm_vec1 * norm_vec2)\n","\n","# Embedding de la question\n","embedding_question = embeddings_hf[0]\n","\n","# Embeddings des documents potentiels\n","embedding_doc1 = embeddings_hf[1]\n","embedding_doc2 = embeddings_hf[2]\n","\n","# Calcul des similarités\n","similarity_q_doc1 = cosine_similarity(embedding_question, embedding_doc1)\n","similarity_q_doc2 = cosine_similarity(embedding_question, embedding_doc2)\n","\n","print(f\"Question : '{textes_hf[0]}'\")\n","print(\"-\" * 30)\n","print(f\"Document 1 : '{textes_hf[1]}'\")\n","print(f\"Similarité avec la question : {similarity_q_doc1:.4f}\")\n","print(\"-\" * 30)\n","print(f\"Document 2 : '{textes_hf[2]}'\")\n","print(f\"Similarité avec la question : {similarity_q_doc2:.4f}\")\n","print(\"-\" * 30)\n","\n","if similarity_q_doc1 > similarity_q_doc2:\n","    print(\"\\nConclusion : Le document 1 est sémantiquement plus proche de la question.\")\n","else:\n","    print(\"\\nConclusion : Le document 2 est sémantiquement plus proche de la question.\")"],"metadata":{"id":"_ZdLmNb-Yedz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Installation de la bibliothèque Mistral AI\n","!pip install mistralai\n","print(\"Bibliothèque Mistral AI installée !\")"],"metadata":{"id":"YObiZdriYeg_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from mistralai import Mistral\n","\n","# Remplacez par votre vraie clé API\n","api_key = \"StthE16bt5IReMHPxgjbwtQLGggjOGtq\"\n","\n","# Initialisation du client avec la version 1.6.0\n","client = Mistral(api_key=api_key)\n","print(\"Client Mistral initialisé.\")\n","\n","# Choix du modèle et définition des messages\n","model = \"mistral-large-latest\"  # Vous pouvez adapter le modèle selon vos besoins\n","messages = [\n","    {\"role\": \"user\", \"content\": \"Quel est le meilleur fromage français ?\"}\n","]\n","\n","# Appel non-streaming de la fonction chat via la méthode complete\n","chat_response = client.chat.complete(\n","    model=model,\n","    messages=messages,\n",")\n","\n","# Affichage de la réponse générée par le modèle\n","print(\"Réponse du modèle :\", chat_response.choices[0].message.content)"],"metadata":{"id":"x1LDwqMtYekX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from mistralai import Mistral\n","from mistralai.models import EmbeddingRequest\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Remplacez par votre vraie clé API\n","api_key = \"\"\n","\n","# Initialisation du client avec la version 0.4.2\n","client = Mistral(api_key=api_key)\n","print(\"Client Mistral initialisé.\")\n","\n","# Textes pour lesquels nous générons des embeddings\n","textes_mistral = [\n","    \"Quelles sont les heures d'ouverture de la mairie ?\",\n","    \"La mairie de Trifouillis-sur-Loire est ouverte du lundi au vendredi de 8h30 à 17h00.\",\n","    \"Le marché hebdomadaire a lieu tous les samedis matin sur la place centrale.\"\n","]\n","\n","# Modèle d'embedding de Mistral\n","model_mistral = \"mistral-embed\"\n","\n","\n","print(f\"\\nGénération des embeddings avec le modèle '{model_mistral}'...\")\n","\n","# Appel à l'API via la méthode create\n","response = client.embeddings.create(\n","    model=model_mistral,\n","    inputs=textes_mistral\n",")\n","\n","# Extraction des embeddings de la réponse\n","embeddings_mistral_raw = response.data\n","# Conversion en array numpy pour faciliter les calculs (chaque objet a un attribut .embedding)\n","embeddings_mistral = np.array([item.embedding for item in embeddings_mistral_raw])\n","\n","print(\"Embeddings Mistral générés !\")\n","print(\"Shape du premier embedding Mistral :\", embeddings_mistral[0].shape)\n","\n","# --- Calcul de similarité ---\n","print(\"\\n--- Calcul de Similarité (Mistral) ---\")\n","embedding_question_mistral = embeddings_mistral[0]\n","embedding_doc1_mistral = embeddings_mistral[1]\n","embedding_doc2_mistral = embeddings_mistral[2]\n","\n","similarity_q_doc1_mistral = cosine_similarity([embedding_question_mistral], [embedding_doc1_mistral])[0][0]\n","similarity_q_doc2_mistral = cosine_similarity([embedding_question_mistral], [embedding_doc2_mistral])[0][0]\n","\n","print(f\"Question : '{textes_mistral[0]}'\")\n","print(\"-\" * 30)\n","print(f\"Document 1 : '{textes_mistral[1]}'\")\n","print(f\"Similarité avec la question : {similarity_q_doc1_mistral:.4f}\")\n","print(\"-\" * 30)\n","print(f\"Document 2 : '{textes_mistral[2]}'\")\n","print(f\"Similarité avec la question : {similarity_q_doc2_mistral:.4f}\")\n","print(\"-\" * 30)\n","\n","if similarity_q_doc1_mistral > similarity_q_doc2_mistral:\n","    print(\"\\nConclusion (Mistral) : Le document 1 est sémantiquement plus proche de la question.\")\n","else:\n","    print(\"\\nConclusion (Mistral) : Le document 2 est sémantiquement plus proche de la question.\")\n","\n","\n"],"metadata":{"id":"39WPSYmBbjyU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Conclusion et Prochaines Étapes\n","\n","Nous avons vu deux approches pour générer des embeddings :\n","\n","#### Hugging Face (sentence-transformers):\n","\n","- Avantages: Gratuit (modèles open source), contrôle total sur le modèle, fonctionne hors ligne une fois téléchargé.\n","\n","- Inconvénients: Nécessite des ressources locales (RAM, CPU/GPU), peut être moins performant que les modèles propriétaires de pointe.\n","\n","#### Mistral AI (API):\n","- Avantages: Modèles très performants, pas de gestion d'infrastructure (serverless), facile à intégrer.\n","\n","- Inconvénients: Coût basé sur l'utilisation (payant), nécessite une connexion internet, dépendance vis-à-vis du fournisseur.\n"],"metadata":{"id":"c4askJJGblpV"}}]}